<div align="center">

  <h1><code>Elixir Queue</code></h1>
</div>

## ðŸ—º Translations
- [ðŸ‡ºðŸ‡¸ English](./README.en_US.md)

## ðŸ¤” MotivaÃ§Ã£o
O motivo principal pelo qual resolvi desenvolver essa fila de processos foi o aprendizado das estruturas e APIs do Erlang/OTP utilizando o Elixir. Provalvemente existem muitas outras filas de processamento de serviÃ§os em segundo plano espalhadas por ai bem mais eficientes do que esta que se encontra aqui. No entanto acredito que para quem estÃ¡ comeÃ§ando Ã© demasiado interessante ter acesso a estruturas mais simples, tanto do ponto de vista de lÃ³gica de programaÃ§Ã£o quanto da perspectiva operacional do OTP. Por isso optei por fazer desde a base um software para execuÃ§Ã£o de processos de forma a conseguir explicar as tomadas de decisÃ£o e, eventualmente, ir corrigindo esse caminho conforme a comunidade demonstre que uma ou outra opÃ§Ã£o Ã© melhor, atravÃ©s de _pull requests_ ou mesmo _issues_ abertas. Tenho certeza que serÃ¡ de grande ajuda para iniciantes e para mim o que for tratado aqui.

## ðŸ“˜ Estrutura
### Fluxo/Diagrama da aplicaÃ§Ã£o
Abaixo um diagrama completo do fluxo de dados e possibilidades de acontecimentos do sistema.
![Diagrama de fluxo de aplicaÃ§Ã£o](https://raw.githubusercontent.com/abmBispo/elixir-queue/master/ElixirQueue.png)

### ElixirQueue.Application
A `Application`desta fila de processos supervisiona os processos que irÃ£o criar/consumir a fila. Eis os filhos da `ElixirQueue.Supervisor`:
```ex
children = [
  {ElixirQueue.Queue, name: ElixirQueue.Queue},
  {DynamicSupervisor, name: ElixirQueue.WorkerSupervisor, strategy: :one_for_one},
  {ElixirQueue.WorkerPool, name: ElixirQueue.WorkerPool},
  {ElixirQueue.EventLoop, []}
]
```
Os filhos, de cima para baixo, representam as seguintes estruturas: `ElixirQueue.Queue` Ã© o `GenServer` que guarda o estado da fila numa tupla; `ElixirQueue.WorkerSupervisor`Ã© o `DynamicSupervisor` dos _workers_ adicionados dinamicamente sempre igual ou menor que o nÃºmero de `schedulers` onlines; `ElixirQueue.WorkerPool`, o processo responsÃ¡vel por guardar os `pids` dos _workers_ e os _jobs_ executados, quer seja com sucesso ou falha; e por Ãºltimo o `ElixirQueue.EventLoop` que Ã© a `Task` que "escuta" as mudanÃ§as na `ElixirQueue.Queue` (ou seja, na fila de processos) e retira _jobs_ para serem executados. O funcionamento especÃ­fico de cada mÃ³dulo eu explicarei conforme for me parecendo Ãºtil.

### ElixirQueue.EventLoop
Eis aqui o processo que controla a retirada de elementos da fila. Um _event loop_ por padrÃ£o Ã© uma funÃ§Ã£o que executa numa iteraÃ§Ã£o/recursÃ£o _pseudo infinita_, uma vez que nÃ£o existe a intenÃ§Ã£o de se quebrar o _loop_. A cada ciclo o _loop_ busca _jobs_ adicionados na fila - ou seja, de certa forma o `ElixirQueue.EventLoop` "escuta" as alteraÃ§Ãµes que ocorreram na fila e reage a partir desses eventos - os direciona ao `ElixirQueue.WorkerPool` para serem executados. Este mÃ³dulo assume o _behaviour_ de `Task` e sua Ãºnica funÃ§Ã£o (`event_loop/0`) nÃ£o retorna nenhum valor tendo em vista que Ã© um _loop_ eterno: ela busca da fila algum elemento e pode receber ou uma tupla `{:ok, job}` com a a tarefa a ser realizada ou uma tupla `{:error, :empty}` para caso a fila esteja vazia; no primeiro caso ele envia para o `ElixirQueue.WorkerPool` a tarefa e executa `event_loop/0` novamente; no segundo caso ele apenas executa a prÃ³pria funÃ§Ã£o recursivamente, continuando o loop atÃ© encontrar algum evento relevante (inserÃ§Ã£o de elemento na fila).

### ElixirQueue.Queue
O mÃ³dulo `ElixirQueue.Queue` guarda o coraÃ§Ã£o do sistema. Aqui os _jobs_ sÃ£o enfileirados para serem consumidos mais tarde pelos _workers_. Ã‰ um `GenServer` sob a supervisÃ£o da `ElixirQueue.Application`, que guarda uma tupla como estado e nessa tupla estÃ£o guardados os jobs - para entender o porquÃª eu preferi por uma tupla ao invÃ©s de uma lista encadeada (`List`), mais abaixo em **AnÃ¡lise de Desempenho** estÃ¡ explicado. A `Queue` Ã© uma estrutura bem simples, com funÃ§Ãµes triviais que basicamente limpam, buscam o primeiro elemento da fila para ser executado e insere um elemento ao fim da fila, de forma a ser executado mais tarde, conforme inserÃ§Ã£o.

### ElixirQueue.WorkerPool
Aqui estÃ¡ o mÃ³dulo capaz de se comunicar tanto com a fila quanto com os _workers_. Quando a _Application_ Ã© iniciada e os processos supervisionados, um dos eventos que ocorre Ã© justamente a inciaÃ§Ã£o dos _workers_ sob a supervisÃ£o do `ElixirQueue.WorkerSupervisor`, um `DynamicSupervisor`, e os seus respectivos _PIDs_ sÃ£o adicionados ao estado do `ElixirQueue.WorkerPool`. AlÃ©m disso, cada worker iniciado dentro do escopo do `WorkerPool` Ã© tambÃ©m supervisionado por esse, o motivo disso serÃ¡ abordado a frente.

Quando o `WorkerPool` recebe o pedido para executar um _job_ ele procura por algum de seus _workers PIDs_ que esteja no estado ocioso, ou seja, sem nenhum job sendo executado no momento. EntÃ£o, para cada _job_ recebido pelo `WorkerPool` atravÃ©s de seu `perform/1`, este vincula o _job_ a um _worker PID_, que passa para o estado de ocupado. Quando o worker termina a execuÃ§Ã£o, limpa seu estado e entÃ£o fica ocioso, esperando por outro _job_. No caso, isso que aqui chamamos de _worker_ nada mais Ã© do que um `Agent` que guarda em seu estado qual job estÃ¡ sendo executado vinculado Ã quele PID; ele serve de lastro limitante uma vez que o `WorkerPool` incia uma nova `Task` para cada _job_. Imagine o cenÃ¡rio onde nÃ£o tivessemos _workers_ para limitar a quantidade de jobs sendo executados concorrentemente: o nosso `EventLoop` inciaria `Task`s a bel prazer, podendo causar grande problemas como estouro de memÃ³ria caso a `Queue` recebesse uma grande carga de _jobs_ de uma sÃ³ vez.

### ElixirQueue.Worker
Neste mÃ³dulo temos os atores responsÃ¡veis por tomar os _jobs_ e executÃ¡-los. PorÃ©m o processo Ã© um pouco mais do que apenas a execuÃ§Ã£o do job; na verdade funciona da seguinte forma:
1. O `Worker` recebe um pedido para performar um certo _job_, adiciona-o ao seu estado interno (estado interno do `Agent` do `PID` passado) e tambÃ©m a uma tabela `:ets` de backup;
2. Depois segue para a execuÃ§Ã£o do _job_ em si. Ã‰ **extremamente necessÃ¡rio lembrarmos** que a execuÃ§Ã£o ocorre no escopo da `Task` invocada pelo `WorkerPool`, e nÃ£o no escopo do processo do Agent. Foi uma opÃ§Ã£o de implementaÃ§Ã£o, poderia ser feito de outras diversas formas porÃ©m escolhi assim pela simplicidade que acredito ter ficado o cÃ³digo.
3. Finalmente, com o _job_ finalizado, o `Worker` volta seu estado interno para ocioso e exclui o backup deste worker da tabela `:ets`.
4. Ademais, com a funÃ§Ã£o do `Worker` tendo sido cumprida, a trilha de execuÃ§Ã£o volta para a `Task` invocada pelo `WorkerPool` e apenas completa a corrida inserindo o _job_ na lista de _jobs_ bem sucedidos.

#### Por que o `WorkerPool` superviosiona `Worker`s? Ou: e se `Worker` morrer, como ficamos?
Como ficou claro na explicaÃ§Ã£o, nÃ£o existe nenhum ponto da trilha de execuÃ§Ã£o dos _jobs_ onde nos preocupamos com a questÃ£o: o que acontece se uma funÃ§Ã£o mal feita for passada como _job_ para a fila de execuÃ§Ã£o, _ou atÃ© mesmo!_, o que ocorre caso algum processo `Agent` `Worker` simplesmente corromper a memÃ³ria e morrer? Pois bem, na intenÃ§Ã£o de escrever o cÃ³digo da forma mais perene possÃ­vel, talvez o mais _Elixir like_ o possÃ­vel, o que foi feito Ã© justamente adicionar garantias de que se os processos falharem (e falharÃ£o!) o sistema consiga reagir de tal forma que mitigue os erros.

Na ocasiÃ£o da falha de algum worker que acarrete em sua morte via _EXIT signal_ o `WorkerPool`, que monitora todos os seus workers via `Process.monitor`, repÃµe este worker morto por outro, adicionando-o ao `WorkerSupervisor`. Com isso tambÃ©m remove o `PID` do `Worker` morto da lista de `PID`s e adiciona o novo. PorÃ©m nÃ£o para por ai: o `WorkerPool` checa por algum backup criado do `Worker` morto e, encontrando, repÃµe o _job_ na fila com seu valor de _attempt_retry_ adicionado de um. O `WorkerPool` sempre irÃ¡ adicionar o _job_ novamente na fila uma quantidade prÃ©-determinada de vezes, definida no arquivo `mix.exs`, no _environment_ da _application_. 

## ðŸƒ AnÃ¡lise de desempenho
### Por que `Tuple` ao invÃ©s de `List`
Para fila de processos funcionar normalmente eu preciso apenas de inserir no final e retirar do inÃ­cio. Claramente isso pode ser feito tanto com `List` quanto com `Tuple`, e acabei optando por tuple pelo simples fato de ser mais rÃ¡pido. Direto do _output_ do Benchee rodando `mix run benchmark.exs` na raiz do projeto:
```
Operating System: Linux
CPU Information: Intel(R) Core(TM) i7-8565U CPU @ 1.80GHz
Number of Available Cores: 8
Available memory: 15.56 GB
Elixir 1.10.2
Erlang 22.3.2

Benchmark suite executing with the following configuration:
warmup: 2 s
time: 5 s
memory time: 0 ns
parallel: 1
inputs: none specified
Estimated total run time: 14 s

Benchmarking Insert element at end of linked list...
Benchmarking Insert element at end of tuple...

Name                                           ips        average  deviation         median         99th %
Insert element at end of tuple              4.89 K      204.42 Î¼s    Â±72.94%      119.45 Î¼s      571.85 Î¼s
Insert element at end of linked list        1.24 K      808.27 Î¼s    Â±54.67%      573.68 Î¼s     1896.52 Î¼s

Comparison: 
Insert element at end of tuple              4.89 K
Insert element at end of linked list        1.24 K - 3.95x slower +603.85 Î¼s
```

### Teste de estresse
Preparei um teste de estresse para a aplicaÃ§Ã£o que enfileira 1000 _fake jobs_, cada um ordenando uma `List` reversamente ordenada com 3 milhÃµes de elementos, utilizando o `Enum.sort/1` (de acordo com a documentaÃ§Ã£o, o algoritmo Ã© um _merge sort_). Para executÃ¡-lo basta entrar no terminal via `iex -S mix` e rodar `ElixirQueue.Fake.populate`; a execuÃ§Ã£o leva alguns minutos (e pelo menos uns 2gb de RAM), e depois vocÃª pode conferir os resultados com `ElixirQueue.Fake.spec`.

## ðŸ’¼ Exemplos de uso
Para ver a fila de processos funcionando basta executar `iex -S mix` na raiz do projeto e utilizar os comandos abaixo. A menos que vocÃª esteja em modo `test`, vocÃª verÃ¡ _logs_ de informaÃ§Ã£o sobre a execuÃ§Ã£o do _job_.

### ElixirQueue.Queue.perform_later/1
Ã‰ possÃ­vel construir a _struct_ do _job_ manualmente e passÃ¡-lo para a fila.
```ex
iex> job = %ElixirQueue.Job{mod: Enum, func: :reverse, args: [[1,2,3,4,5]]}
iex> ElixirQueue.Queue.perform_later(job)
:ok
```

### ElixirQueue.Queue.perform_later/3
AlÃ©m disso tambÃ©m podemos passar manualmente os valores do mÃ³dulo, funÃ§Ã£o e argumentos para `perform_later/3`.
```ex
iex> ElixirQueue.Queue.perform_later(Enum, :reverse, [[1,2,3,4,5]])
:ok
```
